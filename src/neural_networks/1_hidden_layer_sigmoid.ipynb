{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from numpy.random import MT19937\n",
    "from numpy.random import RandomState, SeedSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an output array\n",
    "def target_array(raw_target):\n",
    "    target = []\n",
    "    for i in range(len(raw_target)):\n",
    "        if raw_target[i] == 0:\n",
    "            target.append([1, 0, 0])\n",
    "        elif raw_target[i] == 1:\n",
    "            target.append([0, 1, 0])\n",
    "        else:\n",
    "            target.append([0, 0, 1])\n",
    "    return np.array(target, dtype=\"uint8\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "data = iris.data\n",
    "target = target_array(iris.target)\n",
    "\n",
    "# Mixing data\n",
    "rs1 = RandomState(MT19937(SeedSequence(0)))\n",
    "rs1.shuffle(data)\n",
    "rs2 = RandomState(MT19937(SeedSequence(0)))\n",
    "rs2.shuffle(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid \n",
    "# Activation function\n",
    "def activation_func(x):\n",
    "    z = 1 / (1 + (np.e ** -x))\n",
    "    return z\n",
    "\n",
    "\n",
    "# Derivative of the activation function\n",
    "def deriv_activation_func(x):\n",
    "    z = activation_func(x)\n",
    "    return z * (1 - z)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - input layer  \n",
    "1 - hidden layer  \n",
    "2 - output layer  \n",
    "weights_1_to_2 - Weights linking the hidden layer and the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network learning function\n",
    "def neural_network_training(weights_0_to_1,\n",
    "                            weights_1_to_2,\n",
    "                            data,\n",
    "                            target,\n",
    "                            number_training_data,\n",
    "                            epochs=5,\n",
    "                            alpha=0.5):\n",
    "    epoch_print_step = 100\n",
    "    for epoch in range(epochs):\n",
    "        if epoch % epoch_print_step == 0:\n",
    "            print(f\"\\nepoch: {epoch + 1}\")\n",
    "        for i in range(number_training_data):\n",
    "            # Forward propagation\n",
    "            layer_0 = data[i:i + 1]\n",
    "            layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_to_2)\n",
    "\n",
    "            # Error calculation\n",
    "            layer_2_delta = layer_2 - target[i:i + 1]\n",
    "            layer_1_delta = layer_2_delta.dot(weights_1_to_2.T) * deriv_activation_func(layer_1)\n",
    "            \n",
    "            # Backpropagation\n",
    "            weights_1_to_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "            weights_0_to_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "            \n",
    "            # Output of a part of the data\n",
    "            if epoch % epoch_print_step == 0 and i >= 10 and i <= 13:\n",
    "                print(f\"{np.argmax(layer_2) == np.argmax(target[i])} Error: {np.sum((layer_2 - target[i]) ** 2):.5f}, out = {layer_2}, target = {target[i]}\")\n",
    "  \n",
    "    return weights_0_to_1, weights_1_to_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring parameters for a neural network\n",
    "# epochs = 1000\n",
    "epochs = 401\n",
    "alpha = 0.002\n",
    "\n",
    "number_test_data = 30\n",
    "len_data = len(data)\n",
    "number_training_data = len_data - number_test_data\n",
    "layer_1_size = 7\n",
    "\n",
    "np.random.seed(1)\n",
    "weights_0_to_1 = np.random.rand(len(data[0]), layer_1_size)\n",
    "weights_1_to_2 = np.random.rand(layer_1_size, len(target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1\n",
      "False Error: 25.54148, out = [[3.94733738 2.84074416 2.56352651]], target = [0 1 0]\n",
      "False Error: 25.18416, out = [[3.91645734 2.83583354 2.54464839]], target = [0 1 0]\n",
      "False Error: 24.52973, out = [[3.86569491 2.81239944 2.51024651]], target = [0 1 0]\n",
      "True Error: 19.38313, out = [[3.59542583 2.69429709 2.32113275]], target = [1 0 0]\n",
      "\n",
      "epoch: 101\n",
      "False Error: 0.66315, out = [[0.11318183 0.35784689 0.48782673]], target = [0 1 0]\n",
      "False Error: 0.63308, out = [[-0.04612703  0.43093368  0.55417976]], target = [0 1 0]\n",
      "False Error: 0.66040, out = [[0.17506613 0.36160125 0.47137845]], target = [0 1 0]\n",
      "True Error: 0.01403, out = [[ 0.96828721  0.09436308 -0.06421402]], target = [1 0 0]\n",
      "\n",
      "epoch: 201\n",
      "False Error: 0.56846, out = [[0.0447029  0.40405496 0.45968266]], target = [0 1 0]\n",
      "False Error: 0.53804, out = [[-0.03050791  0.45932017  0.49474313]], target = [0 1 0]\n",
      "False Error: 0.62178, out = [[0.08159361 0.3885914  0.49122522]], target = [0 1 0]\n",
      "True Error: 0.01440, out = [[ 0.95024803  0.08788773 -0.06482225]], target = [1 0 0]\n",
      "\n",
      "epoch: 301\n",
      "True Error: 0.43234, out = [[0.01388147 0.47489267 0.39549012]], target = [0 1 0]\n",
      "True Error: 0.44733, out = [[-0.03369316  0.50605951  0.4496821 ]], target = [0 1 0]\n",
      "False Error: 0.53653, out = [[0.04514553 0.43125892 0.45937322]], target = [0 1 0]\n",
      "True Error: 0.01401, out = [[ 0.98712465  0.08575332 -0.08057761]], target = [1 0 0]\n",
      "\n",
      "epoch: 401\n",
      "True Error: 0.31831, out = [[0.01568118 0.53954479 0.3256399 ]], target = [0 1 0]\n",
      "True Error: 0.35797, out = [[-0.04552394  0.55881723  0.40156406]], target = [0 1 0]\n",
      "True Error: 0.42263, out = [[0.0422516  0.48780884 0.3981273 ]], target = [0 1 0]\n",
      "True Error: 0.00835, out = [[ 1.02568873  0.0638178  -0.06016106]], target = [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Neural network training\n",
    "weights_0_to_1, weights_1_to_2 = neural_network_training(weights_0_to_1,\n",
    "                                                         weights_1_to_2,\n",
    "                                                         data,\n",
    "                                                         target,\n",
    "                                                         number_training_data,\n",
    "                                                         epochs,\n",
    "                                                         alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ñhecking_accuracy(data, target):    \n",
    "    if np.argmax(data) == np.argmax(target):\n",
    "        print(\"True\")\n",
    "        return\n",
    "    print(f\"False: {data}, {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_test(weights_0_to_1,\n",
    "                        weights_1_to_2,\n",
    "                        data,\n",
    "                        target,\n",
    "                        number_test_data,\n",
    "                        len_data):\n",
    "    # print(len_data - number_test_data, len_data)\n",
    "    for i in range(len_data - number_test_data, len_data):\n",
    "        layer_0 = data[i:i + 1]\n",
    "        layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_to_2)\n",
    "        # error = np.sum((layer_2 - target[i]) ** 2)\n",
    "        \n",
    "        Ñhecking_accuracy(layer_2, target[i])\n",
    "        # print(f\"target = out: {np.argmax(target[i]) == np.argmax(layer_2)}\\terror = {error:.4f}\")\n",
    "        # print(f\"target = {target[i]}, out = {layer_2},\\terror = {error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: [[0.0007769  0.37166118 0.6624042 ]], [0 1 0]\n",
      "True\n",
      "False: [[0.05885595 0.28284957 0.73122963]], [0 1 0]\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [[0.0715963  0.29858262 0.68679694]], [0 1 0]\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "neural_network_test(weights_0_to_1,\n",
    "                    weights_1_to_2,\n",
    "                    data,\n",
    "                    target,\n",
    "                    number_test_data,\n",
    "                    len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(weights_0_to_1,\n",
    "                   weights_1_to_2,\n",
    "                   data):\n",
    "    layer_0 = data\n",
    "    layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "    layer_2 = np.dot(layer_1, weights_1_to_2)    \n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [0.05669564 0.34435836 0.62726512], [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    number = np.random.randint(0, 150)\n",
    "    prediction = neural_network(weights_0_to_1,\n",
    "                                weights_1_to_2,\n",
    "                                data[number])\n",
    "    Ñhecking_accuracy(prediction, target[number])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bfd4ff3fa42f792e9ca4f5ed23a406369bd745bdab3b75153b8c4e6e882a8bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('learn_venv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
