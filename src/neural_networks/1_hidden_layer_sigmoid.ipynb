{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                    Description of the dataset\n",
    "#  data : {ndarray, dataframe} of shape (150, 4)\n",
    "#             The data matrix. If `as_frame=True`, `data` will be a pandas\n",
    "#             DataFrame.\n",
    "#         target: {ndarray, Series} of shape (150,)\n",
    "#             The classification target. If `as_frame=True`, `target` will be\n",
    "#             a pandas Series.\n",
    "#         feature_names: list\n",
    "#             The names of the dataset columns.\n",
    "#         target_names: list\n",
    "#             The names of target classes.\n",
    "#         frame: DataFrame of shape (150, 5)\n",
    "#             Only present when `as_frame=True`. DataFrame with `data` and\n",
    "#             `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an output array\n",
    "def target_array(raw_target):\n",
    "    target = []\n",
    "    for i in range(len(raw_target)):\n",
    "        if raw_target[i] == 0:\n",
    "            target.append([1, 0, 0])\n",
    "        elif raw_target[i] == 1:\n",
    "            target.append([0, 1, 0])\n",
    "        else:\n",
    "            target.append([0, 0, 1])\n",
    "    return (np.array(target, dtype=\"uint8\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "data = iris.data\n",
    "target = target_array(iris.target)\n",
    "\n",
    "# Mixing data\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(data)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sigmoid \n",
    "# Activation function\n",
    "def activation_func(x):\n",
    "    z = 1 / (1 + (np.e ** -x))\n",
    "    return z\n",
    "\n",
    "\n",
    "# Derivative of the activation function\n",
    "def deriv_activation_func(x):\n",
    "    z = activation_func(x)\n",
    "    return z * (1 - z)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - input layer  \n",
    "1 - hidden layer  \n",
    "2 - output layer  \n",
    "weights_1_to_2 - Weights linking the hidden layer and the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network learning function\n",
    "def neural_network_training(weights_0_to_1,\n",
    "                            weights_1_to_2,\n",
    "                            data,\n",
    "                            target,\n",
    "                            number_training_data,\n",
    "                            epochs=5,\n",
    "                            alpha=0.5):\n",
    "    epoch_print_step = 100\n",
    "    for epoch in range(epochs):\n",
    "        if epoch % epoch_print_step == 0:\n",
    "            print(f\"\\nepoch: {epoch + 1}\")\n",
    "        for i in range(number_training_data):\n",
    "            # Forward propagation\n",
    "            layer_0 = data[i:i + 1]\n",
    "            layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_to_2)\n",
    "\n",
    "            # Error calculation\n",
    "            layer_2_delta = layer_2 - target[i:i + 1]\n",
    "            layer_1_delta = layer_2_delta.dot(weights_1_to_2.T) * deriv_activation_func(layer_1)\n",
    "            \n",
    "            # Backpropagation\n",
    "            weights_1_to_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "            weights_0_to_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "            \n",
    "            # Output of a part of the data\n",
    "            if epoch % epoch_print_step == 0 and i >= 10 and i <= 13:\n",
    "                print(f\"{np.argmax(layer_2) == np.argmax(target[i])} Error: {np.sum((layer_2 - target[i]) ** 2):.5f}, out = {layer_2}, target = {target[i]}\")\n",
    "  \n",
    "    return weights_0_to_1, weights_1_to_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring parameters for a neural network\n",
    "# epochs = 1000\n",
    "epochs = 401\n",
    "alpha = 0.002\n",
    "\n",
    "number_test_data = 30\n",
    "len_data = len(data)\n",
    "number_training_data = len_data - number_test_data\n",
    "layer_1_size = 6\n",
    "\n",
    "np.random.seed(1)\n",
    "weights_0_to_1 = np.random.rand(len(data[0]), layer_1_size)\n",
    "weights_1_to_2 = np.random.rand(layer_1_size, len(target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1\n",
      "True Error: 18.96789, out = [[2.59977008 3.42636901 2.51432246]], target = [0 1 0]\n",
      "False Error: 18.76972, out = [[2.48188846 3.27912205 2.41269308]], target = [1 0 0]\n",
      "False Error: 20.90407, out = [[2.6055155  3.43673034 2.51797506]], target = [0 0 1]\n",
      "True Error: 17.78250, out = [[2.52926479 3.32898957 2.4415429 ]], target = [0 1 0]\n",
      "\n",
      "epoch: 101\n",
      "False Error: 0.76117, out = [[0.20049072 0.28903263 0.4642218 ]], target = [0 1 0]\n",
      "True Error: 0.14164, out = [[ 0.74402994  0.24701143 -0.12288534]], target = [1 0 0]\n",
      "True Error: 0.17609, out = [[-0.03444744  0.36323985  0.79273988]], target = [0 0 1]\n",
      "False Error: 0.71397, out = [[0.28142636 0.2881704  0.35786704]], target = [0 1 0]\n",
      "\n",
      "epoch: 201\n",
      "False Error: 0.72407, out = [[0.18707383 0.31045278 0.4621676 ]], target = [0 1 0]\n",
      "True Error: 0.10893, out = [[ 0.8327434   0.25118124 -0.13363502]], target = [1 0 0]\n",
      "True Error: 0.17574, out = [[-0.10895017  0.35310323  0.80204892]], target = [0 0 1]\n",
      "False Error: 0.66408, out = [[0.28953883 0.32272463 0.34864042]], target = [0 1 0]\n",
      "\n",
      "epoch: 301\n",
      "False Error: 0.65126, out = [[0.17425506 0.34614303 0.43973909]], target = [0 1 0]\n",
      "True Error: 0.07470, out = [[ 0.84293855  0.20038522 -0.09936483]], target = [1 0 0]\n",
      "True Error: 0.18021, out = [[-0.11444993  0.35372965  0.79508307]], target = [0 0 1]\n",
      "True Error: 0.56567, out = [[0.2665113 0.3753931 0.3232818]], target = [0 1 0]\n",
      "\n",
      "epoch: 401\n",
      "True Error: 0.54875, out = [[0.17921517 0.39672822 0.39076673]], target = [0 1 0]\n",
      "True Error: 0.05903, out = [[ 0.83586433  0.16640835 -0.0663184 ]], target = [1 0 0]\n",
      "True Error: 0.14855, out = [[-0.1056792   0.32115979  0.81497513]], target = [0 0 1]\n",
      "True Error: 0.44396, out = [[0.26076334 0.44513877 0.26094914]], target = [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Neural network training\n",
    "weights_0_to_1, weights_1_to_2 = neural_network_training(weights_0_to_1,\n",
    "                                                         weights_1_to_2,\n",
    "                                                         data,\n",
    "                                                         target,\n",
    "                                                         number_training_data,\n",
    "                                                         epochs,\n",
    "                                                         alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def сhecking_accuracy(data, target):    \n",
    "    if np.argmax(data) == np.argmax(target):\n",
    "        print(\"True\")\n",
    "        return\n",
    "    print(f\"False: {data}, {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_test(weights_0_to_1,\n",
    "                        weights_1_to_2,\n",
    "                        data,\n",
    "                        target,\n",
    "                        number_test_data,\n",
    "                        len_data):\n",
    "    # print(len_data - number_test_data, len_data)\n",
    "    for i in range(len_data - number_test_data, len_data):\n",
    "        layer_0 = data[i:i + 1]\n",
    "        layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_to_2)\n",
    "        # error = np.sum((layer_2 - target[i]) ** 2)\n",
    "        \n",
    "        сhecking_accuracy(layer_2, target[i])\n",
    "        # print(f\"target = out: {np.argmax(target[i]) == np.argmax(layer_2)}\\terror = {error:.4f}\")\n",
    "        # print(f\"target = {target[i]}, out = {layer_2},\\terror = {error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [[0.09925872 0.3790793  0.5091387 ]], [0 1 0]\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [[0.07677834 0.37936422 0.54149024]], [0 1 0]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "neural_network_test(weights_0_to_1,\n",
    "                    weights_1_to_2,\n",
    "                    data,\n",
    "                    target,\n",
    "                    number_test_data,\n",
    "                    len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(weights_0_to_1,\n",
    "                   weights_1_to_2,\n",
    "                   data):\n",
    "    layer_0 = data\n",
    "    layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "    layer_2 = np.dot(layer_1, weights_1_to_2)    \n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [0.12688226 0.40534757 0.46324734], [0 1 0]\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [0.09925872 0.3790793  0.5091387 ], [0 1 0]\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    number = np.random.randint(0, 150)\n",
    "    prediction = neural_network(weights_0_to_1,\n",
    "                                weights_1_to_2,\n",
    "                                data[number])\n",
    "    сhecking_accuracy(prediction, target[number])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bfd4ff3fa42f792e9ca4f5ed23a406369bd745bdab3b75153b8c4e6e882a8bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('learn_venv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
