{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                    Description of the dataset\n",
    "#  data : {ndarray, dataframe} of shape (150, 4)\n",
    "#             The data matrix. If `as_frame=True`, `data` will be a pandas\n",
    "#             DataFrame.\n",
    "#         target: {ndarray, Series} of shape (150,)\n",
    "#             The classification target. If `as_frame=True`, `target` will be\n",
    "#             a pandas Series.\n",
    "#         feature_names: list\n",
    "#             The names of the dataset columns.\n",
    "#         target_names: list\n",
    "#             The names of target classes.\n",
    "#         frame: DataFrame of shape (150, 5)\n",
    "#             Only present when `as_frame=True`. DataFrame with `data` and\n",
    "#             `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an output array\n",
    "def target_array(raw_target):\n",
    "    target = []\n",
    "    for i in range(len(raw_target)):\n",
    "        if raw_target[i] == 0:\n",
    "            target.append([1, 0, 0])\n",
    "        elif raw_target[i] == 1:\n",
    "            target.append([0, 1, 0])\n",
    "        else:\n",
    "            target.append([0, 0, 1])\n",
    "    return (np.array(target, dtype=\"uint8\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "data = iris.data\n",
    "target = target_array(iris.target)\n",
    "\n",
    "# Mixing data\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(data)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU\n",
    "# Activation function\n",
    "def activation_func(x): \n",
    "    z = (x > 0) * x     # returns x if x > 0\n",
    "    return z            # return 0 otherwise\n",
    "\n",
    "\n",
    "# Derivative of the activation function\n",
    "def deriv_activation_func(x):\n",
    "    z = x > 0\n",
    "    return z            # returns 1 for input > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - input layer  \n",
    "1 - hidden layer  \n",
    "2 - output layer  \n",
    "weights_1_to_2 - Weights linking the hidden layer and the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network learning function\n",
    "def neural_network_training(weights_0_to_1,\n",
    "                            weights_1_to_2,\n",
    "                            data,\n",
    "                            target,\n",
    "                            number_training_data,\n",
    "                            epochs=5,\n",
    "                            alpha=0.5):\n",
    "    epoch_print_step = 100\n",
    "    for epoch in range(epochs):\n",
    "        if epoch % epoch_print_step == 0:\n",
    "            print(f\"\\nepoch: {epoch + 1}\")\n",
    "        for i in range(number_training_data):\n",
    "            # Forward propagation\n",
    "            layer_0 = data[i:i + 1]\n",
    "            layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_to_2)\n",
    "\n",
    "            # Error calculation\n",
    "            layer_2_delta = layer_2 - target[i:i + 1]\n",
    "            layer_1_delta = layer_2_delta.dot(weights_1_to_2.T) * deriv_activation_func(layer_1)\n",
    "            \n",
    "            # Backpropagation\n",
    "            weights_1_to_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "            weights_0_to_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "            \n",
    "            # Output of a part of the data\n",
    "            if epoch % epoch_print_step == 0 and i >= 10 and i <= 13:\n",
    "                print(f\"{np.argmax(layer_2) == np.argmax(target[i])} Error: {np.sum((layer_2 - target[i]) ** 2):.5f}, out = {layer_2}, target = {target[i]}\")\n",
    "  \n",
    "    return weights_0_to_1, weights_1_to_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring parameters for a neural network\n",
    "# epochs = 1000\n",
    "epochs = 201\n",
    "alpha = 0.002\n",
    "\n",
    "number_test_data = 30\n",
    "len_data = len(data)\n",
    "number_training_data = len_data - number_test_data\n",
    "layer_1_size = 6\n",
    "\n",
    "np.random.seed(1)\n",
    "weights_0_to_1 = np.random.rand(len(data[0]), layer_1_size)\n",
    "weights_1_to_2 = np.random.rand(layer_1_size, len(target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1\n",
      "False Error: 3.11749, out = [[0.07037773 0.26823311 1.60531944]], target = [0 1 0]\n",
      "False Error: 2.76815, out = [[-0.28749178 -0.16590141  1.04066744]], target = [1 0 0]\n",
      "True Error: 1.56761, out = [[0.53052015 0.86647333 1.73169654]], target = [0 0 1]\n",
      "False Error: 2.48434, out = [[0.08066787 0.25616335 1.38727855]], target = [0 1 0]\n",
      "\n",
      "epoch: 101\n",
      "True Error: 0.24075, out = [[0.02871865 0.55856452 0.21227919]], target = [0 1 0]\n",
      "True Error: 0.01014, out = [[1.04806455 0.08845453 0.00165857]], target = [1 0 0]\n",
      "True Error: 0.06459, out = [[-0.14139986  0.20700459  0.95819907]], target = [0 0 1]\n",
      "True Error: 0.07766, out = [[0.14221233 0.76508296 0.04744698]], target = [0 1 0]\n",
      "\n",
      "epoch: 201\n",
      "True Error: 0.17389, out = [[-0.01031222  0.65753898  0.23770329]], target = [0 1 0]\n",
      "True Error: 0.00960, out = [[ 1.09713311 -0.00216956  0.0126286 ]], target = [1 0 0]\n",
      "True Error: 0.01342, out = [[-0.08563787  0.07785555  0.99525146]], target = [0 0 1]\n",
      "True Error: 0.00421, out = [[0.04025312 0.98584578 0.04889501]], target = [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Neural network training\n",
    "weights_0_to_1, weights_1_to_2 = neural_network_training(weights_0_to_1,\n",
    "                                                         weights_1_to_2,\n",
    "                                                         data,\n",
    "                                                         target,\n",
    "                                                         number_training_data,\n",
    "                                                         epochs,\n",
    "                                                         alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def сhecking_accuracy(data, target):    \n",
    "    if np.argmax(data) == np.argmax(target):\n",
    "        print(\"True\")\n",
    "        return\n",
    "    print(f\"False: {data}, {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_test(weights_0_to_1,\n",
    "                        weights_1_to_2,\n",
    "                        data,\n",
    "                        target,\n",
    "                        number_test_data,\n",
    "                        len_data):\n",
    "    # print(len_data - number_test_data, len_data)\n",
    "    for i in range(len_data - number_test_data, len_data):\n",
    "        layer_0 = data[i:i + 1]\n",
    "        layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_to_2)\n",
    "        # error = np.sum((layer_2 - target[i]) ** 2)\n",
    "        \n",
    "        сhecking_accuracy(layer_2, target[i])\n",
    "        # print(f\"target = out: {np.argmax(target[i]) == np.argmax(layer_2)}\\terror = {error:.4f}\")\n",
    "        # print(f\"target = {target[i]}, out = {layer_2},\\terror = {error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [[-0.00582737  0.37524375  0.50455438]], [0 1 0]\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [[-0.10446375  0.59882329  0.56091953]], [0 0 1]\n",
      "True\n",
      "False: [[-0.06219136  0.5311873   0.49544126]], [0 0 1]\n",
      "True\n",
      "False: [[-0.04882086  0.43178539  0.53268983]], [0 1 0]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "neural_network_test(weights_0_to_1,\n",
    "                    weights_1_to_2,\n",
    "                    data,\n",
    "                    target,\n",
    "                    number_test_data,\n",
    "                    len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(weights_0_to_1,\n",
    "                   weights_1_to_2,\n",
    "                   data):\n",
    "    layer_0 = data\n",
    "    layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "    layer_2 = np.dot(layer_1, weights_1_to_2)    \n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [-0.00582737  0.37524375  0.50455438], [0 1 0]\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [-0.10446375  0.59882329  0.56091953], [0 0 1]\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    number = np.random.randint(0, 150)\n",
    "    prediction = neural_network(weights_0_to_1,\n",
    "                                weights_1_to_2,\n",
    "                                data[number])\n",
    "    сhecking_accuracy(prediction, target[number])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bfd4ff3fa42f792e9ca4f5ed23a406369bd745bdab3b75153b8c4e6e882a8bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('learn_venv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
