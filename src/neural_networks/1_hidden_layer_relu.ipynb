{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from numpy.random import MT19937\n",
    "from numpy.random import RandomState, SeedSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                    Description of the dataset\n",
    "#  data : {ndarray, dataframe} of shape (150, 4)\n",
    "#             The data matrix. If `as_frame=True`, `data` will be a pandas\n",
    "#             DataFrame.\n",
    "#         target: {ndarray, Series} of shape (150,)\n",
    "#             The classification target. If `as_frame=True`, `target` will be\n",
    "#             a pandas Series.\n",
    "#         feature_names: list\n",
    "#             The names of the dataset columns.\n",
    "#         target_names: list\n",
    "#             The names of target classes.\n",
    "#         frame: DataFrame of shape (150, 5)\n",
    "#             Only present when `as_frame=True`. DataFrame with `data` and\n",
    "#             `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an output array\n",
    "def target_array(raw_target):\n",
    "    target = []\n",
    "    for i in range(len(raw_target)):\n",
    "        if raw_target[i] == 0:\n",
    "            target.append([1, 0, 0])\n",
    "        elif raw_target[i] == 1:\n",
    "            target.append([0, 1, 0])\n",
    "        else:\n",
    "            target.append([0, 0, 1])\n",
    "    return np.array(target, dtype=\"uint8\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "data = iris.data\n",
    "target = target_array(iris.target)\n",
    "\n",
    "# Mixing data\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(data)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(target)\n",
    "\n",
    "\n",
    "rs1 = RandomState(MT19937(SeedSequence(123456789)))\n",
    "rs1.shuffle(data)\n",
    "rs2 = RandomState(MT19937(SeedSequence(123456789)))\n",
    "rs2.shuffle(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU\n",
    "# Activation function\n",
    "def activation_func(x): \n",
    "    z = (x > 0) * x     # returns x if x > 0\n",
    "    return z            # return 0 otherwise\n",
    "\n",
    "\n",
    "# Derivative of the activation function\n",
    "def deriv_activation_func(x):\n",
    "    z = x > 0\n",
    "    return z            # returns 1 for input > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - input layer  \n",
    "1 - hidden layer  \n",
    "2 - output layer  \n",
    "weights_1_to_2 - Weights linking the hidden layer and the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network learning function\n",
    "def neural_network_training(weights_0_to_1,\n",
    "                            weights_1_to_2,\n",
    "                            data,\n",
    "                            target,\n",
    "                            number_training_data,\n",
    "                            epochs=5,\n",
    "                            alpha=0.5):\n",
    "    epoch_print_step = 100\n",
    "    for epoch in range(epochs):\n",
    "        if epoch % epoch_print_step == 0:\n",
    "            print(f\"\\nepoch: {epoch + 1}\")\n",
    "        for i in range(number_training_data):\n",
    "            # Forward propagation\n",
    "            layer_0 = data[i:i + 1]\n",
    "            layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_to_2)\n",
    "\n",
    "            # Error calculation\n",
    "            layer_2_delta = layer_2 - target[i:i + 1]\n",
    "            layer_1_delta = layer_2_delta.dot(weights_1_to_2.T) * deriv_activation_func(layer_1)\n",
    "            \n",
    "            # Backpropagation\n",
    "            weights_1_to_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "            weights_0_to_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "            \n",
    "            # Output of a part of the data\n",
    "            if epoch % epoch_print_step == 0 and i >= 10 and i <= 13:\n",
    "                print(f\"{np.argmax(layer_2) == np.argmax(target[i])} Error: {np.sum((layer_2 - target[i]) ** 2):.5f}, out = {layer_2}, target = {target[i]}\")\n",
    "  \n",
    "    return weights_0_to_1, weights_1_to_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring parameters for a neural network\n",
    "# epochs = 1000\n",
    "epochs = 201\n",
    "alpha = 0.002\n",
    "\n",
    "number_test_data = 30\n",
    "len_data = len(data)\n",
    "number_training_data = len_data - number_test_data\n",
    "layer_1_size = 7\n",
    "\n",
    "np.random.seed(1)\n",
    "weights_0_to_1 = np.random.rand(len(data[0]), layer_1_size)\n",
    "weights_1_to_2 = np.random.rand(layer_1_size, len(target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1\n",
      "True Error: 3.85272, out = [[1.40380717 1.83493981 1.08853956]], target = [0 1 0]\n",
      "True Error: 1.12542, out = [[0.74288711 1.44316717 0.61411869]], target = [0 1 0]\n",
      "False Error: 1.30621, out = [[0.40479657 0.94812762 0.23021712]], target = [1 0 0]\n",
      "False Error: 6.12320, out = [[1.62512891 1.84752127 1.26233901]], target = [0 0 1]\n",
      "\n",
      "epoch: 101\n",
      "True Error: 0.00088, out = [[-0.01817917  1.010468    0.02106531]], target = [0 1 0]\n",
      "True Error: 0.09958, out = [[ 0.12294345  0.7105184  -0.02585526]], target = [0 1 0]\n",
      "True Error: 0.00303, out = [[ 0.97125593  0.04513733 -0.01284231]], target = [1 0 0]\n",
      "True Error: 0.04945, out = [[-0.08275579  0.14175212  0.84996512]], target = [0 0 1]\n",
      "\n",
      "epoch: 201\n",
      "True Error: 0.00415, out = [[-0.0426412   1.04665585  0.01238989]], target = [0 1 0]\n",
      "True Error: 0.09373, out = [[ 0.1289781   0.72395444 -0.0298366 ]], target = [0 1 0]\n",
      "True Error: 0.00041, out = [[ 1.01340754  0.00902618 -0.01231756]], target = [1 0 0]\n",
      "True Error: 0.03065, out = [[-0.06613946  0.09350144  0.86757204]], target = [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Neural network training\n",
    "weights_0_to_1, weights_1_to_2 = neural_network_training(weights_0_to_1,\n",
    "                                                         weights_1_to_2,\n",
    "                                                         data,\n",
    "                                                         target,\n",
    "                                                         number_training_data,\n",
    "                                                         epochs,\n",
    "                                                         alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def сhecking_accuracy(data, target):    \n",
    "    if np.argmax(data) == np.argmax(target):\n",
    "        print(\"True\")\n",
    "        return\n",
    "    print(f\"False: {data}, {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_test(weights_0_to_1,\n",
    "                        weights_1_to_2,\n",
    "                        data,\n",
    "                        target,\n",
    "                        number_test_data,\n",
    "                        len_data):\n",
    "    # print(len_data - number_test_data, len_data)\n",
    "    for i in range(len_data - number_test_data, len_data):\n",
    "        layer_0 = data[i:i + 1]\n",
    "        layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_to_2)\n",
    "        # error = np.sum((layer_2 - target[i]) ** 2)\n",
    "        \n",
    "        сhecking_accuracy(layer_2, target[i])\n",
    "        # print(f\"target = out: {np.argmax(target[i]) == np.argmax(layer_2)}\\terror = {error:.4f}\")\n",
    "        # print(f\"target = {target[i]}, out = {layer_2},\\terror = {error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False: [[-0.02197351  0.27398408  0.6847794 ]], [0 1 0]\n",
      "True\n",
      "False: [[0.03292013 0.47738165 0.51623802]], [0 1 0]\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "neural_network_test(weights_0_to_1,\n",
    "                    weights_1_to_2,\n",
    "                    data,\n",
    "                    target,\n",
    "                    number_test_data,\n",
    "                    len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(weights_0_to_1,\n",
    "                   weights_1_to_2,\n",
    "                   data):\n",
    "    layer_0 = data\n",
    "    layer_1 = activation_func(np.dot(layer_0, weights_0_to_1))\n",
    "    layer_2 = np.dot(layer_1, weights_1_to_2)    \n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    number = np.random.randint(0, 150)\n",
    "    prediction = neural_network(weights_0_to_1,\n",
    "                                weights_1_to_2,\n",
    "                                data[number])\n",
    "    сhecking_accuracy(prediction, target[number])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bfd4ff3fa42f792e9ca4f5ed23a406369bd745bdab3b75153b8c4e6e882a8bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('learn_venv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
